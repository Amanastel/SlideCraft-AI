###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> CustomGPT4o {\n  provider openai\n  options {\n    model \"gpt-4o\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT4oMini {\n  provider openai\n  retry_policy Exponential\n  options {\n    model \"gpt-4o-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet {\n  provider anthropic\n  options {\n    model \"claude-3-5-sonnet-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-haiku-20240307\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT4oMini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  // Strategy is optional\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  // Strategy is optional\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
    "email_parser.baml": "// file: email_parser.baml\n\n// First, we define the \"shape\" of the data we want to extract.\n// This is like defining a Pydantic model or a TypeScript interface.\n\nenum Urgency {\n  LOW\n  NORMAL\n  HIGH\n  CRITICAL\n}\n\nclass ExtractedInfo {\n  fullName string @description(\"The full name of the customer, if mentioned.\")\n  emailAddress string @description(\"The email address of the customer, if found in the body.\")\n  requestDetails string @description(\"A summary of what the customer is asking for.\")\n  urgencyLevel Urgency @description(\"The inferred urgency of the customer's request.\")\n}\n\n\nfunction ExtractEmailDetails(email_text: string) -> ExtractedInfo {\n  // We specify which LLM client to use.\n  // This 'OpenAI' client would be configured elsewhere (e.g., in a .env or a config file)\n  // with your API key and potentially default model.\n    client \"openai/gpt-4o\"\n\n  // This is the prompt sent to the LLM.\n  // Notice how we can embed the input 'email_text' directly.\n  // The magic is that BAML will try to make the LLM's output conform to the 'ExtractedInfo' class.\n  prompt #\"\n  Parse the following email content and extract the requested information.\n  Return the output as a JSON object matching the schema for 'ExtractedInfo'.\n\n\n  Email Content:\n  ---\n  {{ email_text }}\n  ---\n\n   {{ ctx.output_format }}\n\n  Extracted Information:\n  \"#\n}\n\n// We can also have functions that call other functions, or use classifiers.\n// For instance, a more sophisticated version might have a separate classifier for urgency.\n// function ClassifyUrgency(text_content: String) -> Urgency { ... }\n\n\n// Test the function with a sample email. Open the VSCode playground to run this.\n",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.89.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "instruction_planner.baml": "\nclass Tool {\n  name string @description(\"The name of the tool function\")\n  description string @description(\"Description of what the tool does\")\n  parameters Parameter[] @description(\"List of parameters the tool accepts\")\n  returnType string @description(\"The type of value this tool returns\")\n}\n\n// Define the Parameter type for tool inputs\nclass Parameter {\n  name string @description(\"The name of the parameter\")\n  type string @description(\"The data type of the parameter (string, number, boolean, etc.)\")\n  description string @description(\"Description of the parameter\")\n  required bool @description(\"Whether the parameter is required\")\n}\n\n// Define the ToolCall type for tool execution steps\nclass ToolCall {\n  toolName string @description(\"The name of the tool to call\")\n  arguments map<string, string> @description(\"Map of argument name to value\")\n  resultName string @description(\"Name to assign to the result of this tool call\")\n  description string @description(\"Human-readable description of this step\")\n  dependsOn string[] @description(\"List of previous step resultNames this step depends on\")\n}\n\n// Define the Plan type\nclass Plan {\n  steps ToolCall[] @description(\"The sequence of tool calls to execute\")\n}\n\n// The main function that generates a plan from instructions and available tools\nfunction GeneratePlan(instructions: string, tools: Tool[]) -> Plan {\n  client \"openai/gpt-4\"\n  \n  prompt #\"\n    You are a planning assistant that converts natural language instructions into a sequence of tool calls.\n\n    Available tools:\n    {% for tool in tools %}\n    - {{ tool.name }}: {{ tool.description }}\n      Parameters:\n      {% for param in tool.parameters %}\n        - {{ param.name }} ({{ param.type }}{% if param.required %}, required{% endif %}): {{ param.description }}\n      {% endfor %}\n      Returns: {{ tool.returnType }}\n    {% endfor %}\n\n    User instructions: {{ instructions }}\n\n    Create a plan to carry out these instructions using the available tools. For each step:\n    1. Identify which tool to use\n    2. Determine the arguments for the tool call\n    3. Name the result that will be produced\n    4. Specify any dependencies on previous steps\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n// Test case for the Math operations example\ntest MathOperationsTest {\n  functions [GeneratePlan]\n  args {\n    instructions \"Get the sum of ten and twenty, then multiply it by hundred\"\n    tools [\n      {\n        name \"sum\"\n        description \"Adds two numbers together\"\n        parameters [\n          {\n            name \"a\"\n            type \"number\"\n            description \"First number to add\"\n            required true\n          },\n          {\n            name \"b\"\n            type \"number\"\n            description \"Second number to add\"\n            required true\n          }\n        ]\n        returnType \"number\"\n      },\n      {\n        name \"multiply\"\n        description \"Multiplies two numbers together\"\n        parameters [\n          {\n            name \"a\"\n            type \"number\"\n            description \"First number to multiply\"\n            required true\n          },\n          {\n            name \"b\"\n            type \"number\"\n            description \"Second number to multiply\"\n            required true\n          }\n        ]\n        returnType \"number\"\n      },\n      {\n        name \"subtract\"\n        description \"Subtracts second number from the first\"\n        parameters [\n          {\n            name \"a\"\n            type \"number\"\n            description \"Number to subtract from\"\n            required true\n          },\n          {\n            name \"b\"\n            type \"number\"\n            description \"Number to subtract\"\n            required true\n          }\n        ]\n        returnType \"number\"\n      },\n      {\n        name \"divide\"\n        description \"Divides first number by the second\"\n        parameters [\n          {\n            name \"a\"\n            type \"number\"\n            description \"Numerator\"\n            required true\n          },\n          {\n            name \"b\"\n            type \"number\"\n            description \"Denominator (cannot be zero)\"\n            required true\n          }\n        ]\n        returnType \"number\"\n      }\n    ]\n  }\n}\n",
    "main.baml": "class Tools{\n    name string\n    args map<string, string>\n    @description(#\"\n        Arguments for the tool as Strings key-value pairs.\n    \"#)\n\n}\n\n\n\nfunction Plans(instructions: string, tools: string) -> Tool[] {\n    client \"openai/gpt-4o\"\n    prompt #\"\n        You are an AI Planner. Given the user's instructions and a comma-separated list of available tools, \n        generate a plan that uses the tools step by step to achieve the desired outcome.\n\n\n        Tools available:\n        {{ tools | join(\", \") }}\n        \n        Instructions:\n        {{ instructions }}\n        \n        \n        Please provide a detailed plan for executing the instructions using the tools.\n    \"#\n}\n\n",
    "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\n  client \"openai/gpt-4o\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
}

def get_baml_files():
    return file_map